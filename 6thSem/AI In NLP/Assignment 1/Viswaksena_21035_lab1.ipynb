{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Name : J Viswaksena\n",
        "# RollNo : AM.EN.U4AIE21035"
      ],
      "metadata": {
        "id": "iAc1GjwS9IiN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BprR9FJI2Fkv"
      },
      "source": [
        "**21AIE314 lab1**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shcy6_R6--3q"
      },
      "source": [
        "### **             Assignment1**\n",
        "Write a paragraph about any large language models and save this as llm.text file.\n",
        "\n",
        "Read and display this file with Python program.\n",
        "\n",
        "Extract sentences and words from this file.\n",
        "\n",
        "If there are any stop-words, remove them.\n",
        "\n",
        "Identify any 10 most frequently used tokens.\n",
        "\n",
        "Identify the stems and lemma for those words.\n",
        "\n",
        "Check for any words that are not lemmatised.\n",
        "\n",
        "Count number of stop words and non stop-words.\n",
        "\n",
        "Translate any ten of these words into your native language.\n",
        "\n",
        "If there are any spelling mistakes, remove the identified ones.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSMXikLk8i9x"
      },
      "source": [
        " # Write a paragraph about any large language models and save this as llm.text file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "S6lZFvJn3HZO",
        "outputId": "59b2971a-9c21-4763-e580-043974b68b53"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c1df3975-9032-414c-b625-d828c0ec2fb0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c1df3975-9032-414c-b625-d828c0ec2fb0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving llm.txt to llm.txt\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eL8LrJSQ80T0"
      },
      "source": [
        "# Read and display this file with Python program."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "HHaaw3M47Zdq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3ff1073d-689b-4906-9547-0a0a4f6f153c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LL.M., short for Master of Laws, stands as an eminent postgraduate degree targeted at individuals with a foundational background in law or substantial experience within the legal realm. It serves as an avenue for legal professionals to deepen their understanding of specific legl domains, broaden their comprehension of legal systems, or specialize in international law.\n",
            "The primary impetus behind pursuing an LL.M. lies in the opportunity it presents for specialization beyond the scope coverd in a basic law degree. Students can delve into diverse specializations such as tax law, human rights, intellectual property, or international arbitration. The LL.M. curriculum entails a comprehensive exploration of legal theories, principles, and practical applications pertinent to the chosen field of study.\n",
            "A hallmark of LL.M. programs is their flexiility and diversity, with many universities offering a wide array of specialization options. This flexibility enables students to tailor their sudies in alignment with their professional aspirations and personal interests. Whether one seeks a career in corporate law, environmental law, or criminal justice, there's likely an LL.M. program crafted to meet those objectives.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "f = open('llm.txt','r',encoding='utf8',errors = 'ignore')\n",
        "lines = f.read()\n",
        "print(lines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PibfuAY82_L"
      },
      "source": [
        "# Extract sentences from this file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "YWdAIqW-yks1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "213b220c-ac9a-46bc-d2e7-256673ab903d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "emTraWnR7t4J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d6594a8b-af8a-425b-ffbe-3b0d23d32c97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n"
          ]
        }
      ],
      "source": [
        "# Sentence tokenization\n",
        "tokens = nltk.sent_tokenize(lines)\n",
        "print(len(tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5psLnWM085lz"
      },
      "source": [
        "# Extract words from this file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "J3_jYUxF8JYl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "8368b96b-7fbc-4d76-f36d-208218a38d67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "203\n"
          ]
        }
      ],
      "source": [
        "# Word Tokenization\n",
        "tokens = nltk.word_tokenize(lines)\n",
        "print(len(tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70_jc8akGqb1"
      },
      "source": [
        "# Count number of stop words and non stop-words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "WxWJLmh4Gv4g",
        "outputId": "874a4b64-f8a7-45da-afa0-fcbc3652e64d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop Words:  183\n",
            "Non Stop Words:  119\n"
          ]
        }
      ],
      "source": [
        "non_stopwords = []\n",
        "stop_word = []\n",
        "\n",
        "for word2 in tokens:\n",
        "  if word2 in stop_words:\n",
        "    stop_word.append(word2)\n",
        "\n",
        "for word in tokens:\n",
        "  if word not in stop_words:\n",
        "    # print(word)\n",
        "    non_stopwords.append(word)\n",
        "\n",
        "print(\"Stop Words: \",len(stop_words))\n",
        "print(\"Non Stop Words: \",len(non_stopwords))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZpLeQHS9I34"
      },
      "source": [
        "# If there are any stop-words, remove them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "izxGB3hO8Vu6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c40db9d8-5ef7-4d5f-92fa-919173d956fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "0Z1RYZDa9och",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "30e6e887-a981-4253-92ea-2b6f84fc22ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "179\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "print(len(stop_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "kkksYEkj-FAf"
      },
      "outputs": [],
      "source": [
        "stop_words.extend([',',';','also','.'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "KxVkHFNB-X8D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ff3d5b90-6e86-4970-9234-abea077f59a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['LL.M.', 'short', 'Master', 'Laws', 'stands', 'eminent', 'postgraduate', 'degree', 'targeted', 'individuals', 'foundational', 'background', 'law', 'substantial', 'experience', 'within', 'legal', 'realm', 'It', 'serves', 'avenue', 'legal', 'professionals', 'deepen', 'understanding', 'specific', 'legl', 'domains', 'broaden', 'comprehension', 'legal', 'systems', 'specialize', 'international', 'law', 'The', 'primary', 'impetus', 'behind', 'pursuing', 'LL.M', 'lies', 'opportunity', 'presents', 'specialization', 'beyond', 'scope', 'coverd', 'basic', 'law', 'degree', 'Students', 'delve', 'diverse', 'specializations', 'tax', 'law', 'human', 'rights', 'intellectual', 'property', 'international', 'arbitration', 'The', 'LL.M', 'curriculum', 'entails', 'comprehensive', 'exploration', 'legal', 'theories', 'principles', 'practical', 'applications', 'pertinent', 'chosen', 'field', 'study', 'A', 'hallmark', 'LL.M', 'programs', 'flexiility', 'diversity', 'many', 'universities', 'offering', 'wide', 'array', 'specialization', 'options', 'This', 'flexibility', 'enables', 'students', 'tailor', 'sudies', 'alignment', 'professional', 'aspirations', 'personal', 'interests', 'Whether', 'one', 'seeks', 'career', 'corporate', 'law', 'environmental', 'law', 'criminal', 'justice', \"'s\", 'likely', 'LL.M', 'program', 'crafted', 'meet', 'objectives']\n",
            "LL.M. short Master Laws stands eminent postgraduate degree targeted individuals foundational background law substantial experience within legal realm It serves avenue legal professionals deepen understanding specific legl domains broaden comprehension legal systems specialize international law The primary impetus behind pursuing LL.M lies opportunity presents specialization beyond scope coverd basic law degree Students delve diverse specializations tax law human rights intellectual property international arbitration The LL.M curriculum entails comprehensive exploration legal theories principles practical applications pertinent chosen field study A hallmark LL.M programs flexiility diversity many universities offering wide array specialization options This flexibility enables students tailor sudies alignment professional aspirations personal interests Whether one seeks career corporate law environmental law criminal justice 's likely LL.M program crafted meet objectives\n"
          ]
        }
      ],
      "source": [
        "newlist = []\n",
        "for word in tokens:\n",
        "  if word not in stop_words:\n",
        "    # print(word)\n",
        "    newlist.append(word)\n",
        "print(newlist)\n",
        "print(*newlist)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmW6bhHG-0x-"
      },
      "source": [
        "# Identify any 10 most frequently used tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "PyQYeC1u-sSK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4e49ab58-8528-489f-8b20-d27dd98c60ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<FreqDist with 104 samples and 119 outcomes>\n"
          ]
        }
      ],
      "source": [
        "from nltk.probability import FreqDist\n",
        "fdist = FreqDist(newlist)\n",
        "print(fdist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "MybYP6J7_Pvf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "975118f0-4b8d-4088-e29d-c8896552f987"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('law', 6),\n",
              " ('legal', 4),\n",
              " ('LL.M', 4),\n",
              " ('degree', 2),\n",
              " ('international', 2),\n",
              " ('The', 2),\n",
              " ('specialization', 2),\n",
              " ('LL.M.', 1),\n",
              " ('short', 1),\n",
              " ('Master', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ],
      "source": [
        "fdist.most_common(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "m4BqHjzV_a16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fbdf349a-62ab-4301-d50d-0692882c4fa6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'law'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 128
        }
      ],
      "source": [
        "fdist.max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bc2hHBJFBN_0"
      },
      "source": [
        "# Identify the stems for those words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "qk-oeqesDpkS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "97a454ae-f6c6-4159-96de-752c11974b47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ],
      "source": [
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "OIQsTZ4LBvDM"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "fJQm3DddCAmT"
      },
      "outputs": [],
      "source": [
        "porter = PorterStemmer()\n",
        "lancaster=LancasterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "LAnr8rtcBJUE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "01a406c1-51cb-4285-dd7f-e3a621e99940"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------Porter Stemmer--------------------\n",
            "ll.m.\n",
            "short\n",
            "master\n",
            "law\n",
            "stand\n",
            "emin\n",
            "postgradu\n",
            "degre\n",
            "target\n",
            "individu\n",
            "foundat\n",
            "background\n",
            "law\n",
            "substanti\n",
            "experi\n",
            "within\n",
            "legal\n",
            "realm\n",
            "it\n",
            "serv\n",
            "avenu\n",
            "legal\n",
            "profession\n",
            "deepen\n",
            "understand\n",
            "specif\n",
            "legl\n",
            "domain\n",
            "broaden\n",
            "comprehens\n",
            "legal\n",
            "system\n",
            "special\n",
            "intern\n",
            "law\n",
            "the\n",
            "primari\n",
            "impetu\n",
            "behind\n",
            "pursu\n",
            "ll.m\n",
            "lie\n",
            "opportun\n",
            "present\n",
            "special\n",
            "beyond\n",
            "scope\n",
            "coverd\n",
            "basic\n",
            "law\n",
            "degre\n",
            "student\n",
            "delv\n",
            "divers\n",
            "special\n",
            "tax\n",
            "law\n",
            "human\n",
            "right\n",
            "intellectu\n",
            "properti\n",
            "intern\n",
            "arbitr\n",
            "the\n",
            "ll.m\n",
            "curriculum\n",
            "entail\n",
            "comprehens\n",
            "explor\n",
            "legal\n",
            "theori\n",
            "principl\n",
            "practic\n",
            "applic\n",
            "pertin\n",
            "chosen\n",
            "field\n",
            "studi\n",
            "a\n",
            "hallmark\n",
            "ll.m\n",
            "program\n",
            "flexiil\n",
            "divers\n",
            "mani\n",
            "univers\n",
            "offer\n",
            "wide\n",
            "array\n",
            "special\n",
            "option\n",
            "thi\n",
            "flexibl\n",
            "enabl\n",
            "student\n",
            "tailor\n",
            "sudi\n",
            "align\n",
            "profession\n",
            "aspir\n",
            "person\n",
            "interest\n",
            "whether\n",
            "one\n",
            "seek\n",
            "career\n",
            "corpor\n",
            "law\n",
            "environment\n",
            "law\n",
            "crimin\n",
            "justic\n",
            "'s\n",
            "like\n",
            "ll.m\n",
            "program\n",
            "craft\n",
            "meet\n",
            "object\n"
          ]
        }
      ],
      "source": [
        "print(\"--------------------Porter Stemmer--------------------\")\n",
        "for word in newlist:\n",
        "  print(porter.stem(word))\n",
        "# #proide a word to be stemmed\n",
        "# print(\"Porter Stemmer\")\n",
        "\n",
        "# print(porter.stem(newlist))\n",
        "# print(\"Lancaster Stemmer\")\n",
        "# print(lancaster.stem(newlist))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "TmSG9uwFBsMV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "9f5da8b5-3113-47eb-ab43-161b8490c4bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------Lancaster Stemmer--------------------\n",
            "ll.m.\n",
            "short\n",
            "mast\n",
            "law\n",
            "stand\n",
            "emin\n",
            "postgradu\n",
            "degr\n",
            "target\n",
            "individ\n",
            "found\n",
            "background\n",
            "law\n",
            "subst\n",
            "expery\n",
            "within\n",
            "leg\n",
            "realm\n",
            "it\n",
            "serv\n",
            "avenu\n",
            "leg\n",
            "profess\n",
            "deep\n",
            "understand\n",
            "spec\n",
            "legl\n",
            "domain\n",
            "broad\n",
            "comprehend\n",
            "leg\n",
            "system\n",
            "spec\n",
            "intern\n",
            "law\n",
            "the\n",
            "prim\n",
            "impet\n",
            "behind\n",
            "pursu\n",
            "ll.m\n",
            "lie\n",
            "opportun\n",
            "pres\n",
            "spec\n",
            "beyond\n",
            "scop\n",
            "coverd\n",
            "bas\n",
            "law\n",
            "degr\n",
            "stud\n",
            "delv\n",
            "divers\n",
            "spec\n",
            "tax\n",
            "law\n",
            "hum\n",
            "right\n",
            "intellect\n",
            "property\n",
            "intern\n",
            "arbit\n",
            "the\n",
            "ll.m\n",
            "curricul\n",
            "entail\n",
            "comprehend\n",
            "expl\n",
            "leg\n",
            "the\n",
            "principl\n",
            "pract\n",
            "apply\n",
            "pertin\n",
            "chos\n",
            "field\n",
            "study\n",
            "a\n",
            "hallmark\n",
            "ll.m\n",
            "program\n",
            "flexiil\n",
            "divers\n",
            "many\n",
            "univers\n",
            "off\n",
            "wid\n",
            "array\n",
            "spec\n",
            "opt\n",
            "thi\n",
            "flex\n",
            "en\n",
            "stud\n",
            "tail\n",
            "sudy\n",
            "align\n",
            "profess\n",
            "aspir\n",
            "person\n",
            "interest\n",
            "wheth\n",
            "on\n",
            "seek\n",
            "car\n",
            "corp\n",
            "law\n",
            "environ\n",
            "law\n",
            "crimin\n",
            "just\n",
            "'s\n",
            "lik\n",
            "ll.m\n",
            "program\n",
            "craft\n",
            "meet\n",
            "object\n"
          ]
        }
      ],
      "source": [
        "print(\"--------------------Lancaster Stemmer--------------------\")\n",
        "for word in newlist:\n",
        "  print(lancaster.stem(word))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WC-jSfCCs4j"
      },
      "source": [
        "# Identify the lemma for those words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "_01HL1ZwCnCe"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "dfBXNZOJCxtE"
      },
      "outputs": [],
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "gJT2rOmNC0VB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "5849dde4-2db6-4727-cfae-b1755cefdf9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LL.M. -> LL.M.\n",
            "short -> short\n",
            "Master -> Master\n",
            "Laws -> Laws\n",
            "stands -> stand\n",
            "eminent -> eminent\n",
            "postgraduate -> postgraduate\n",
            "degree -> degree\n",
            "targeted -> targeted\n",
            "individuals -> individual\n",
            "foundational -> foundational\n",
            "background -> background\n",
            "law -> law\n",
            "substantial -> substantial\n",
            "experience -> experience\n",
            "within -> within\n",
            "legal -> legal\n",
            "realm -> realm\n",
            "It -> It\n",
            "serves -> serf\n",
            "avenue -> avenue\n",
            "legal -> legal\n",
            "professionals -> professional\n",
            "deepen -> deepen\n",
            "understanding -> understanding\n",
            "specific -> specific\n",
            "legl -> legl\n",
            "domains -> domain\n",
            "broaden -> broaden\n",
            "comprehension -> comprehension\n",
            "legal -> legal\n",
            "systems -> system\n",
            "specialize -> specialize\n",
            "international -> international\n",
            "law -> law\n",
            "The -> The\n",
            "primary -> primary\n",
            "impetus -> impetus\n",
            "behind -> behind\n",
            "pursuing -> pursuing\n",
            "LL.M -> LL.M\n",
            "lies -> lie\n",
            "opportunity -> opportunity\n",
            "presents -> present\n",
            "specialization -> specialization\n",
            "beyond -> beyond\n",
            "scope -> scope\n",
            "coverd -> coverd\n",
            "basic -> basic\n",
            "law -> law\n",
            "degree -> degree\n",
            "Students -> Students\n",
            "delve -> delve\n",
            "diverse -> diverse\n",
            "specializations -> specialization\n",
            "tax -> tax\n",
            "law -> law\n",
            "human -> human\n",
            "rights -> right\n",
            "intellectual -> intellectual\n",
            "property -> property\n",
            "international -> international\n",
            "arbitration -> arbitration\n",
            "The -> The\n",
            "LL.M -> LL.M\n",
            "curriculum -> curriculum\n",
            "entails -> entail\n",
            "comprehensive -> comprehensive\n",
            "exploration -> exploration\n",
            "legal -> legal\n",
            "theories -> theory\n",
            "principles -> principle\n",
            "practical -> practical\n",
            "applications -> application\n",
            "pertinent -> pertinent\n",
            "chosen -> chosen\n",
            "field -> field\n",
            "study -> study\n",
            "A -> A\n",
            "hallmark -> hallmark\n",
            "LL.M -> LL.M\n",
            "programs -> program\n",
            "flexiility -> flexiility\n",
            "diversity -> diversity\n",
            "many -> many\n",
            "universities -> university\n",
            "offering -> offering\n",
            "wide -> wide\n",
            "array -> array\n",
            "specialization -> specialization\n",
            "options -> option\n",
            "This -> This\n",
            "flexibility -> flexibility\n",
            "enables -> enables\n",
            "students -> student\n",
            "tailor -> tailor\n",
            "sudies -> sudies\n",
            "alignment -> alignment\n",
            "professional -> professional\n",
            "aspirations -> aspiration\n",
            "personal -> personal\n",
            "interests -> interest\n",
            "Whether -> Whether\n",
            "one -> one\n",
            "seeks -> seek\n",
            "career -> career\n",
            "corporate -> corporate\n",
            "law -> law\n",
            "environmental -> environmental\n",
            "law -> law\n",
            "criminal -> criminal\n",
            "justice -> justice\n",
            "'s -> 's\n",
            "likely -> likely\n",
            "LL.M -> LL.M\n",
            "program -> program\n",
            "crafted -> crafted\n",
            "meet -> meet\n",
            "objectives -> objective\n",
            "Lemmatized words: ['LL.M.', 'short', 'Master', 'Laws', 'stand', 'eminent', 'postgraduate', 'degree', 'targeted', 'individual', 'foundational', 'background', 'law', 'substantial', 'experience', 'within', 'legal', 'realm', 'It', 'serf', 'avenue', 'legal', 'professional', 'deepen', 'understanding', 'specific', 'legl', 'domain', 'broaden', 'comprehension', 'legal', 'system', 'specialize', 'international', 'law', 'The', 'primary', 'impetus', 'behind', 'pursuing', 'LL.M', 'lie', 'opportunity', 'present', 'specialization', 'beyond', 'scope', 'coverd', 'basic', 'law', 'degree', 'Students', 'delve', 'diverse', 'specialization', 'tax', 'law', 'human', 'right', 'intellectual', 'property', 'international', 'arbitration', 'The', 'LL.M', 'curriculum', 'entail', 'comprehensive', 'exploration', 'legal', 'theory', 'principle', 'practical', 'application', 'pertinent', 'chosen', 'field', 'study', 'A', 'hallmark', 'LL.M', 'program', 'flexiility', 'diversity', 'many', 'university', 'offering', 'wide', 'array', 'specialization', 'option', 'This', 'flexibility', 'enables', 'student', 'tailor', 'sudies', 'alignment', 'professional', 'aspiration', 'personal', 'interest', 'Whether', 'one', 'seek', 'career', 'corporate', 'law', 'environmental', 'law', 'criminal', 'justice', \"'s\", 'likely', 'LL.M', 'program', 'crafted', 'meet', 'objective']\n"
          ]
        }
      ],
      "source": [
        "lemmatized_words = []\n",
        "\n",
        "for word in newlist:\n",
        "    lemma = lemmatizer.lemmatize(word)\n",
        "    print(word, \"->\", lemma)\n",
        "    lemmatized_words.append(lemma)\n",
        "\n",
        "print('Lemmatized words:', lemmatized_words)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fi1UwQYCFxdU"
      },
      "source": [
        "# Check for any words that are not lemmatised."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "f9e9YisLDHhO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "7ad5f812-d061-4b02-b539-55716d292f55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non-lemmatized words: ['stands', 'individuals', 'serves', 'professionals', 'domains', 'systems', 'lies', 'presents', 'specializations', 'rights', 'entails', 'theories', 'principles', 'applications', 'programs', 'universities', 'options', 'students', 'aspirations', 'interests', 'seeks', 'objectives']\n"
          ]
        }
      ],
      "source": [
        "non_lemmatized_words = []\n",
        "\n",
        "for word, lemma in zip(newlist, lemmatized_words):\n",
        "    if word != lemma:\n",
        "        non_lemmatized_words.append(word)\n",
        "\n",
        "print(\"Non-lemmatized words:\", non_lemmatized_words)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Translate any ten of these words into your native language."
      ],
      "metadata": {
        "id": "ltEQUd3w-ISL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "yX9s2gLCGWZO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "631384bd-fcfd-4bea-cf58-959e184c703a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: translate in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from translate) (8.1.7)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from translate) (4.9.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from translate) (2.31.0)\n",
            "Requirement already satisfied: libretranslatepy==2.1.1 in /usr/local/lib/python3.10/dist-packages (from translate) (2.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->translate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->translate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->translate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->translate) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "pip install translate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from translate import Translator\n",
        "\n",
        "translator= Translator(to_lang=\"te\")\n",
        "\n",
        "for j in newlist[:10]:\n",
        "  translation = translator.translate(j)\n",
        "  print(j,'-->',translation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2qR1K5ru-Ogc",
        "outputId": "aeee8e00-d639-472e-e2dc-a9656919aa80"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LL.M. --> LL.M.\n",
            "short --> పొట్టి\n",
            "Master --> మాస్టర్\n",
            "Laws --> చట్టాలు\n",
            "stands --> స్టాండ్ ‌ లు\n",
            "eminent --> ప్రముఖ\n",
            "postgraduate --> పోస్ట్ గ్రాడ్యుయేట్\n",
            "degree --> patta\n",
            "\n",
            "targeted --> లక్ష్యంగా\n",
            "individuals --> వ్యక్తులు\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# If there are any spelling mistakes, remove the identified ones."
      ],
      "metadata": {
        "id": "bZp5HBoB_RBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyspellchecker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "mMjPJ151-f3W",
        "outputId": "d7bc5c23-6eca-4b25-a3e4-68133ff82c9f"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspellchecker in /usr/local/lib/python3.10/dist-packages (0.8.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from hashlib import new\n",
        "from spellchecker import SpellChecker\n",
        "\n",
        "spell = SpellChecker()\n",
        "c=0\n",
        "print(\"Before Spell Check: \",len(newlist))\n",
        "for k in newlist:\n",
        "  # misspelled = spell.unknown(k)\n",
        "  # print(misspelled)\n",
        "  # print(spell.correction(misspelled))\n",
        "  # # Get a list of `likely` options\n",
        "  # print(spell.candidates(misspelled))\n",
        "  if spell.correction(k) != k:\n",
        "    c+=1\n",
        "    print(k)\n",
        "    newlist.remove(k)\n",
        "print('Number of misspelled words',c)\n",
        "print('After Spell Check: ',len(newlist))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ix6dyCzh_Txy",
        "outputId": "546057b5-0293-494c-dc89-7fa59e47ae8d"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Spell Check:  119\n",
            "LL.M.\n",
            "legl\n",
            "LL.M\n",
            "coverd\n",
            "LL.M\n",
            "LL.M\n",
            "flexiility\n",
            "sudies\n",
            "'s\n",
            "LL.M\n",
            "Number of misspelled words 10\n",
            "After Spell Check:  109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HqFYcZzwAcir"
      },
      "execution_count": 141,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}